# Server Configuration
PORT=3000
NODE_ENV=development

# Twilio Configuration (Required)
TWILIO_ACCOUNT_SID=ACxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
TWILIO_AUTH_TOKEN=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
TWILIO_WELCOME_GREETING="Hello! How can I assist you today?"

# Meta Llama API Configuration (Required)
LLAMA_API_KEY=your_api_key_here
LLAMA_API_URL=https://api.llama.com/v1/chat/completions
LLAMA_MODEL=Llama-4-Maverick-17B-128E-Instruct-FP8
LLAMA_MAX_TOKENS=150
LLAMA_TEMPERATURE=0.7
LLAMA_SYSTEM_PROMPT="You are a helpful voice assistant. Keep responses concise and natural for voice conversation."

# WebSocket Configuration
WS_PATH=/ws
WS_MAX_PAYLOAD=1048576

# External URL (Replace with your ngrok or public URL)
PUBLIC_URL=https://your-domain.ngrok.io

# Feature Flags
ENABLE_DTMF=true
ENABLE_INTERRUPTIONS=true

# Logging
LOG_LEVEL=info
LOG_FORMAT=simple  # 'simple' for colored output, 'json' for production